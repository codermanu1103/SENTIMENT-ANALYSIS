{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26c6ae2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Cell 1: Import Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fc94189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 22146 reviews: 11036 positive, 11110 negative\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Cell 2: Load IMDb Dataset\n",
    "# Update path if needed\n",
    "dataset_path = 'aclImdb/train'  # <-- Change this if it's in a different location\n",
    "\n",
    "data = load_files(dataset_path, categories=['pos', 'neg'], encoding='utf-8')\n",
    "X, y = data.data, data.target\n",
    "\n",
    "print(f\"Loaded {len(X)} reviews: {sum(y==1)} positive, {sum(y==0)} negative\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd117293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Cell 3: Vectorize with TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split into training and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_vect, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1592e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Œ Cell 4: Train Model (Logistic Regression)\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60dcdc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Accuracy: 0.8848758465011287\n",
      "\n",
      "ðŸ“‹ Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.89      2268\n",
      "           1       0.87      0.90      0.88      2162\n",
      "\n",
      "    accuracy                           0.88      4430\n",
      "   macro avg       0.89      0.89      0.88      4430\n",
      "weighted avg       0.89      0.88      0.88      4430\n",
      "\n",
      "\n",
      "ðŸ§® Confusion Matrix:\n",
      " [[1973  295]\n",
      " [ 215 1947]]\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Cell 5: Evaluate Model\n",
    "print(\"âœ… Accuracy:\", accuracy_score(y_val, y_pred))\n",
    "print(\"\\nðŸ“‹ Classification Report:\\n\", classification_report(y_val, y_pred))\n",
    "print(\"\\nðŸ§® Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b86296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Top Positive Words:\n",
      "['superb', 'loved', 'fun', 'amazing', 'favorite', 'wonderful', 'perfect', 'best', 'excellent', 'great']\n",
      "\n",
      "ðŸ”» Top Negative Words:\n",
      "['worst', 'bad', 'waste', 'awful', 'boring', 'poor', 'worse', 'terrible', 'dull', 'unfortunately']\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Œ Cell 6: Top Predictive Words\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "coeffs = model.coef_[0]\n",
    "\n",
    "# Top 10 words for each class\n",
    "top_pos = np.argsort(coeffs)[-10:]\n",
    "top_neg = np.argsort(coeffs)[:10]\n",
    "\n",
    "print(\"ðŸ” Top Positive Words:\")\n",
    "print([feature_names[i] for i in top_pos])\n",
    "\n",
    "print(\"\\nðŸ”» Top Negative Words:\")\n",
    "print([feature_names[i] for i in top_neg])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31aaa30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8731923312449951\n"
     ]
    }
   ],
   "source": [
    "test_data = load_files('aclImdb/test', categories=['pos', 'neg'], encoding='utf-8')\n",
    "X_test = vectorizer.transform(test_data.data)\n",
    "y_test = test_data.target\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
